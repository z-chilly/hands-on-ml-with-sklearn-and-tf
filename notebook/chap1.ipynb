{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Machine Learning Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.advantage\n",
    "Machine Learning is great for:  \n",
    "• Problems for which existing solutions require a lot of hand-tuning or long lists of rules: one Machine Learning algorithm can often simplify code and perform better.  \n",
    "• Complex problems for which there is no good solution at all using a traditional approach: the best Machine Learning techniques can find a solution.  \n",
    "• Fluctuating environments: a Machine Learning system can adapt to new data.  \n",
    "• Getting insights about complex problems and large amounts of data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.category\n",
    "## 2.1 Supervised/Unsupervised Learning\n",
    "**supervised**  \n",
    "A typical supervised learning task is classification.   \n",
    "Another typical task is to predict a target numeric value, such as the price of a car, given a set of features (mileage, age, brand, etc.) called predictors. This sort of task is called regression.  \n",
    "Here are some of the most important supervised learning algorithms (covered in this book):  \n",
    "• k-Nearest Neighbors  \n",
    "• Linear Regression  \n",
    "• Logistic Regression  \n",
    "• Support Vector Machines (SVMs)  \n",
    "• Decision Trees and Random Forests  \n",
    "• Neural networks2  \n",
    "\n",
    "\n",
    "**Unsupervised learning**  \n",
    "In unsupervised learning, as you might guess, the training data is unlabeled  \n",
    "• Clustering  \n",
    "— k-Means  \n",
    "— Hierarchical Cluster Analysis (HCA)   \n",
    "— Expectation Maximization  \n",
    "• Visualization and dimensionality reduction   \n",
    "— Principal Component Analysis (PCA) — Kernel PCA  \n",
    "— Locally-Linear Embedding (LLE)  \n",
    "— t-distributed Stochastic Neighbor Embedding (t-SNE)  \n",
    "• Association rule learning  \n",
    "— Apriori — Eclat  \n",
    "\n",
    "\n",
    "*It is often a good idea to try to reduce the dimension of your train‐ ing data using a dimensionality reduction algorithm before you feed it to another Machine Learning algorithm (such as a supervised learning algorithm). It will run much faster, the data will take up less disk and memory space, and in some cases it may also perform better.*  \n",
    " \n",
    "\n",
    "**Semisupervised learning**  \n",
    "deal with partially labeled training data  \n",
    "\n",
    "\n",
    "**Reinforcement Learning**  \n",
    "agent,rewards/penalties,policy  \n",
    "\n",
    "\n",
    "## 2.2batch and online learning\n",
    "**Batch learning**  \n",
    "must be trained using all the available data  \n",
    "First the system is trained, and then it is launched into production and runs without learning anymore; it just applies what it has learned.   \n",
    "\n",
    "\n",
    "**Online learning**  \n",
    "In online learning, you train the system incrementally by feeding it data instances sequentially, either individually or by small groups called mini-batches.  \n",
    "once an online learning system has learned about new data instances, it does not need them anymore, so you can discard them  \n",
    "\n",
    "\n",
    "*This whole process is usually done offline (i.e., not on the live sys‐ tem), so online learning can be a confusing name. Think of it as incremental learning.*  \n",
    "\n",
    "learning rate  \n",
    "high:rapidly adapt to new data, but it will also tend to quickly forget the old data  \n",
    "\n",
    "\n",
    "## 2.3 Instance-Based Versus Model-Based Learning\n",
    "**Instance-based learning**  \n",
    "the system learns the examples by heart, then generalizes to new cases using a similarity measure  \n",
    "\n",
    "\n",
    "**Model-based learning**  \n",
    "make predictions  \n",
    "specify a performance measure:either define a utility function (or fitness function) that measures how good your model is, or you can define a cost function that measures how bad it is  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt    \n",
    "import numpy as py    #matrix\n",
    "import pandas as pd    #数据分析包\n",
    "import sklearn\n",
    "\n",
    "#load the data\n",
    "oecd_bli = pd.read_csv(\"oecd_bli_2015.csv\",thousands=',')\n",
    "gdp_per_capita = pd.read_csv(\"gdp_per_capita.csv\",thousands=',',delimiter='\\t',encoding='latin1',na_values=\"n\\a\")\n",
    "\n",
    "#visualize the data\n",
    "country_stats.plot(kind='scatter',x=\"GDP per capita\",y='Life satisfaction')\n",
    "plt.show()\n",
    "\n",
    "#select a linear model\n",
    "lin_reg_model = sklearn.linear_model.LinearRegression()    #or KNN\n",
    "clf = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "#train the model\n",
    "lin_reg_model.fit(X,y)\n",
    "\n",
    "#make a prediction for cyprus\n",
    "X_new = [[22587]]\n",
    "print(lin_reg_model.predict(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. main challenges\n",
    "Insufficient Quantity of Training Data  \n",
    "Nonrepresentative Training Data  \n",
    "Poor-Quality Data  \n",
    "Irrelevant Features  \n",
    "Overfitting the Training Data  \n",
    "Underfitting the Training Data  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
